\chapter{Conclusions and Future Work}
\label{conclusion}
In this project, we introduce the concept of \textit{counting feature} which is composed of \textit{frequency feature} and \textit{average CTR feature}, and prove that for the same dataset, counting feature space is a non-linear transformation of binary feature space, and the CTR prediction performance in terms of AUC of counting feature using GBRT algorithm is comparable to that of binary feature using linear logistic regression model. Unlike previous and current researches which focus more on the improvement of machine learning model and algorithm in CTR prediction problem, we turn to the more fundamental, but more crucial to the industry, research field, which is feature engineering. We show that counting feature can not only transform the extremely high dimension feature space into low, scalable, interpretable space, but also remain the comparable CTR prediction performance as traditional method, which will largely decrease the memory and time cost for industry. 

To the best of our knowledge, our work is the first one to systematically research on statistical feature, namely counting feature, even though statistical feature has been used by a small range of companies in daily business, our work is the first one to not only provide experimental result, but also mathematical derivation. The most important thing is, we present that counting feature can partly solve the classical \textit{cold start} problem to extend the knowledge from one advertising campaign to the others, we show that without updating old model parameters we can still obtain high performance using counting feature in the context of \textit{cross-domain learning} problem. There are few literature studying on cross-domain learning problem in the field of online advertising, and we are the first one with simplest implementation and solid backups.

However, the research in of our work is not ended. Firstly, we need more dataset to test our theory since currently we only have two datasets which are from iPinYou and Adform, also more linear and non-linear machine learning algorithms should be used to validate the correctness of our theory. Secondly, now we can only do the offline experiment, however, since for cross-learning problem, commonly the new income data should be in the format of stream, we already mimic the process of data stream, but implementing the experiment online will be absolutely what we will do next. Lastly, for the cross-learning problem, now we assume that the marginal distribution of the joint probability distribution of feature and label space are the same so that directly using model from old campaign to new ones is feasible, however, the covariate or domain shift is inevitable in the real world machine learning problem, a multitask optimization method to not only minimise the different between the feature distribution of source and target campaign, but also classifier difference should be studied to increase the CTR prediction further.
